{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General setup\n",
    "\n",
    "To make sure things are working and `hepdata_lib` is available, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hepdata_lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhepdata_lib\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hepdata_lib'"
     ]
    }
   ],
   "source": [
    "import hepdata_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your HEPData submission\n",
    "\n",
    "The `Submission` object represents the whole HEPData entry and thus carries the top-level meta data that is equally valid for all the tables and variables you may want to enter. The object is also used to create the physical submission files you will upload to the HEPData web interface.\n",
    "\n",
    "When using `hepdata_lib` to make an entry, you always need to create a `Submission` object. Let's do that now, and then add data to it step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepdata_lib import Submission\n",
    "submission = Submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, a `Submission` should contain details on the actual analysis such as it's abstract as well as links to the actual publication. The abstract should be in a plain text file. For `inspire` there's a special `record_id`, while for links to `arXiv` etc. one should use plain hyperlinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.read_abstract(\"abstract.txt\")\n",
    "#submission.add_link(\"Webpage with all figures and tables\", \"https://cms-results.web.cern.ch/cms-results/public-results/publications/B2G-16-029/\")\n",
    "#submission.add_link(\"arXiv\", \"http://arxiv.org/abs/arXiv:1802.09407\")\n",
    "#submission.add_record_id(1657397, \"inspire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding CalcHEP model and LHE headers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a table/figure\n",
    "\n",
    "In HEPData, figures and table will both be `Table` objects. The example here shows reading a plain text file containing the signal effiency times acceptance as a function of resonance mass for different signal models. The file has been uploaded to the `example_files` directory. For your submission, create a new directory, e.g. using the analysis identifier.\n",
    "\n",
    "Let's have a look at the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: example_inputs/effacc_signal.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!head example_inputs/effacc_signal.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is the mass value, the other columns contain the efficiency times acceptance values.\n",
    "\n",
    "Let's create the table/figure. First, we need to give it a name, which is usually just the identifier in the paper, here \"Figure 1\". The table also needs a description, which is usually the caption. You also need to describe the location, i.e. where to find it in the publication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hepdata_lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhepdata_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Table\n\u001b[1;32m      2\u001b[0m table \u001b[38;5;241m=\u001b[39m Table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdditional Figure 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m table\u001b[38;5;241m.\u001b[39mdescription \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSignal selection efficiency times acceptance as a function of resonance mass for a spin-2 bulk graviton decaying to WW and a spin-1 W\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m decaying to WZ.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hepdata_lib'"
     ]
    }
   ],
   "source": [
    "from hepdata_lib import Table\n",
    "table = Table(\"Additional Figure 1\")\n",
    "table.description = \"Signal selection efficiency times acceptance as a function of resonance mass for a spin-2 bulk graviton decaying to WW and a spin-1 W' decaying to WZ.\"\n",
    "table.location = \"Data from additional Figure 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to provide more information on what is actually shown, which is done via `keywords`. The ones that are available can be taken from the documentation:\n",
    "- [Observables](https://hepdata-submission.readthedocs.io/en/latest/keywords/observables.html)\n",
    "- [Phrases](https://hepdata-submission.readthedocs.io/en/latest/keywords/phrases.html)\n",
    "- [Particles](https://hepdata-submission.readthedocs.io/en/latest/keywords/partlist.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.keywords[\"observables\"] = [\"ACC\", \"EFF\"]\n",
    "table.keywords[\"reactions\"] = [\"P P --> GRAVITON --> W+ W-\", \"P P --> WPRIME --> W+/W- Z0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in the file. For this purpose, `numpy` is very handy. Since the first two rows are the header, we skip them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt(\"example_inputs/effacc_signal.txt\", skiprows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` stores the content as arrays. You can actually see that the entry that was labelled as `NaN` is correctly read in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+03 4.65100000e-01 4.51360000e-01]\n",
      " [1.20000000e+03 5.03360000e-01 5.10900000e-01]\n",
      " [1.40000000e+03 5.12600000e-01 5.40160000e-01]\n",
      " [1.60000000e+03 5.24740000e-01 5.51300000e-01]\n",
      " [1.80000000e+03 5.31000000e-01 5.67240000e-01]\n",
      " [2.00000000e+03 5.39100000e-01 5.72800000e-01]\n",
      " [2.50000000e+03 5.49430894e-01 5.85602410e-01]\n",
      " [3.00000000e+03 5.53780000e-01 5.89520000e-01]\n",
      " [3.50000000e+03 5.62160000e-01 6.03240000e-01]\n",
      " [4.00000000e+03 5.64538153e-01            nan]\n",
      " [4.50000000e+03 5.66820000e-01 5.99780000e-01]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use this for our `Variable` definitions. The x-axis is usually the independent variable (`is_independent=True`), whereas the other ones are dependent (i.e. a function of the former). You also need to declare whether the variable is binned or not as well as the units. Similar as for the `keywords` used above, it is again important to provide additional information that can be found via the HEPData web interface using the observables and particles linked above. The values assigned are just slices of the `data` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepdata_lib import Variable\n",
    "d = Variable(\"Resonance mass\", is_independent=True, is_binned=False, units=\"GeV\")\n",
    "d.values = data[:,0]\n",
    "\n",
    "BulkG = Variable(\"Efficiency times acceptance\", is_independent=False, is_binned=False, units=\"\")\n",
    "BulkG.values = data[:,1]\n",
    "BulkG.add_qualifier(\"Efficiency times acceptance\", \"Bulk graviton --> WW\")\n",
    "BulkG.add_qualifier(\"SQRT(S)\", 13, \"TeV\")\n",
    "\n",
    "Wprime = Variable(\"Efficiency times acceptance\", is_independent=False, is_binned=False, units=\"\")\n",
    "Wprime.values = data[:,2]\n",
    "Wprime.add_qualifier(\"Efficiency times acceptance\", \"Wprime --> WZ\")\n",
    "Wprime.add_qualifier(\"SQRT(S)\", 13, \"TeV\")\n",
    "\n",
    "table.add_variable(d)\n",
    "table.add_variable(BulkG)\n",
    "table.add_variable(Wprime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of a plot, you should also add the original figure itself. `hepdata_lib` will take care of creating the thumbnail as well. Just add the figure as below.\n",
    "\n",
    "*WARNING*: This needs `ImageMagick` to be installed (this is the case when running on Binder and SWAN with LCG_94 or later). Executing the following line will fail if it is missing. In this case, comment out this line and restart from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.add_image(\"example_inputs/signalEffVsMass.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all that's needed for the table/figure. We still need it to the submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.add_table(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've added all tables/figures and the general submission details, you should add a few more keywords to all tables for better identification and searchability, e.g. the centre-of-mass energy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in submission.tables:\n",
    "    table.keywords[\"cmenergies\"] = [13000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to create the submission for the upload. Here, we choose `example_output` as output directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"example_output\"\n",
    "submission.create_files(outdir,remove_old=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the working directory, you will now find a `submission.tar.gz` file, which you can use for uploading to your HEPData sandbox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls submission.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the `example_output` directory will contain the generated `yaml` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additional_figure_1.yaml  signalEffVsMass.png       submission.yaml           thumb_signalEffVsMass.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls example_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
